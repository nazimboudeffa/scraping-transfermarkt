{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48d2d36-cdd9-4aaf-a0cb-0186b28896ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae7083d-08cc-40f8-948d-ba2dccf0c517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary headers to store the User-Agent string for the request\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0;Win64) AppleWebkit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "087fb1c4-803a-4279-8d60-76e8fe98538e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the player links from the csv file\n",
    "df_links = pd.read_csv('output/player_links.csv')\n",
    "\n",
    "# Convert the 'URL' column of the dataframe to a list\n",
    "links = df_links['URL'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b522ca-1928-48ca-af8d-8b0b8d25b0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucas Perri , Dec 10, 1997 (27) , ['Brazil', 'Italy'] , Olympique Lyon , adidas , 10.00m , 28 , - , 1 / - / -\n",
      "Outfitter not found\n",
      "Rémy Descamps , Jun 25, 1996 (28) , ['France'] , Olympique Lyon , None , 1.50m , - , - , - / - / -\n",
      "Index Error : Sleeping for 10 seconds before retrying\n",
      "Index Error : Sleeping for 10 seconds before retrying\n",
      "Index Error : Sleeping for 10 seconds before retrying\n"
     ]
    }
   ],
   "source": [
    "# List to store data of each player in the form of a dictionary\n",
    "list_of_row_dicts = []\n",
    "\n",
    "# Loop through each link to scrape player data\n",
    "for link in links:\n",
    "\n",
    "    # Keep trying until the request is successful\n",
    "    while True:\n",
    "        try:\n",
    "            # Make a GET request to the link\n",
    "            request = rq.get(link,headers=headers)\n",
    "            \n",
    "            # Extraire les morceaux utiles\n",
    "            parts = link.split('/')\n",
    "            player_slug = parts[3]\n",
    "            player_id = parts[-1]\n",
    "            \n",
    "            # Construire l'URL de stats détaillées Ligue 1 saison 2024\n",
    "            competition = \"FR1\"\n",
    "            season = \"2024\"        \n",
    "            detailed_url = f\"https://www.transfermarkt.com/{player_slug}/leistungsdatendetails/spieler/{player_id}/wettbewerb/{competition}/saison/{season}\"\n",
    "            request_detailed = rq.get(detailed_url, headers=headers)\n",
    "        \n",
    "            # Use BeautifulSoup to parse the HTML content of the page\n",
    "            soup = bs(request.text, 'html.parser')\n",
    "            soup_detailed = bs(request_detailed.text, 'html.parser')\n",
    "\n",
    "            # Find all <span> tags in the HTML\n",
    "            title_spans = soup.find_all('span')\n",
    "\n",
    "            table = soup_detailed.find('table', class_='items')\n",
    "            rows = table.find_all('tr', {'class': ['odd', 'even']})\n",
    "                       \n",
    "            # Break out of the loop if the request is successful\n",
    "            break\n",
    "        except AttributeError:\n",
    "            # Print error message and wait for 10 seconds before retrying\n",
    "            print('Index Error : Sleeping for 10 seconds before retrying')\n",
    "            sleep(10)\n",
    "            \n",
    "    try:\n",
    "        name = ' '.join([word for word in soup.find('h1').text.split() if not any(i.isdigit() for i in word)]).strip()\n",
    "    except IndexError:\n",
    "        name = None\n",
    "        print ('Name not found')\n",
    "\n",
    "    try:\n",
    "        date_of_birth = [span.find_next('span').text for span in title_spans if 'Date of birth/Age:' in span.text][0].strip()\n",
    "    except IndexError:\n",
    "        date_of_birth = None\n",
    "        print ('DoB not found')\n",
    "\n",
    "    try:\n",
    "        citizenship = [span.find_next('span').text.strip().split('\\xa0\\xa0') for span in title_spans if 'Citizenship:' in span.text][0]\n",
    "    except AttributeError:\n",
    "        citizenship = None\n",
    "        print ('Citizenship not found')\n",
    "\n",
    "    try:\n",
    "        current_club = [span.find_next('span').text for span in title_spans if 'Current club:' in span.text][0].strip()\n",
    "    except IndexError:\n",
    "        current_club = None\n",
    "        print ('Current club not found')\n",
    "\n",
    "    try:\n",
    "        outfitter = [span.find_next('span').text for span in title_spans if 'Outfitter:' in span.text][0].strip()\n",
    "    except IndexError:\n",
    "        outfitter = None\n",
    "        print ('Outfitter not found')\n",
    "\n",
    "    try:\n",
    "        mv = [span.next_sibling.strip() for span in title_spans if '€' in span.text][0].strip()\n",
    "        korm = [span.find_next('span').text for span in title_spans if '€' in span.text][0].strip()\n",
    "        mv = mv + korm\n",
    "    except IndexError:\n",
    "        mv = None\n",
    "        print ('MV not found')\n",
    "\n",
    "    try:\n",
    "        # Récupérer toutes les <td>\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')   \n",
    "            # Le nombre de buts est à l'index 4 (commence à 0)\n",
    "            matchs = cells[3].text.strip()\n",
    "            goals = cells[4].text.strip()\n",
    "            assists = cells[5].text.strip()\n",
    "    except IndexError:\n",
    "        goals = None\n",
    "        print('Stats not found')\n",
    "            \n",
    "    row_dic = {\n",
    "    'PLAYER_URL' : link,\n",
    "    'NAME' : name,\n",
    "    'DATE_OF_BIRTH' : date_of_birth,\n",
    "    'CITIZENSHIP': citizenship,\n",
    "    'CURRENT_CLUB' : current_club,\n",
    "    'OUTFITTER' : outfitter,\n",
    "    'MV' : mv,\n",
    "    'MATCHS' : matchs,\n",
    "    'GOALS' : goals,\n",
    "    'ASSISTS' : assists\n",
    "    }\n",
    "    list_of_row_dicts.append(row_dic)\n",
    "            \n",
    "    print(name,',',date_of_birth,',',citizenship,',',current_club,',',outfitter,',',mv,',',matchs,',',goals,',',assists)\n",
    "    sleep(randint(1,3))\n",
    "\n",
    "df = pd.DataFrame(list_of_row_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3855654d-7e35-4115-b143-e14ac59b71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output/player_info_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6926f7-32b8-401a-8b86-f9fb8f1c8d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
