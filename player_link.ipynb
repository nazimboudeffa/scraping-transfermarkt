{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9028fd2-22aa-43cd-a9f1-623bede42491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c155992-61ce-4992-8df4-e05b2e2fc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary headers to store the User-Agent string for the request\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0;Win64) AppleWebkit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c03ad73a-460e-4575-8163-5649a25f3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a list of URLs for 10 top football teams\n",
    "teams = [\n",
    "    'https://www.transfermarkt.com/olympique-lyon/startseite/verein/1041'\n",
    "]\n",
    "\n",
    "# Store a range of years from 2012 to 2022\n",
    "years = range(2024,2025)\n",
    "\n",
    "# Initialize an empty list to store player links\n",
    "players = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea5ae68-3d90-4661-9247-042a41039cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olympique-lyon 2024\n"
     ]
    }
   ],
   "source": [
    "# Loop through the teams list\n",
    "for team in teams:\n",
    "    # Loop through the years list\n",
    "    for y in years:\n",
    "        # Concatenate the team name and year to create the URL\n",
    "        team_url_season = str(team) + '?saison_id='+ str(y)\n",
    "        \n",
    "        # Use a while loop to ensure the code runs until the data is extracted\n",
    "        while True:\n",
    "            try:\n",
    "                # Make a GET request to the URL and parse the HTML\n",
    "                request = rq.get(team_url_season, headers=headers)\n",
    "                soup = bs(request.text, 'html.parser')\n",
    "                # Find the first table with class \"items\" and store it in players_table\n",
    "                players_table = soup.find_all('table', class_='items')[0]\n",
    "                # Find all links within the players_table and store them in links\n",
    "                links = players_table.find_all('a')\n",
    "                # Extract the href attribute from the links and store it in links\n",
    "                links = [l.get(\"href\") for l in links]\n",
    "                # Filter the links list to include only player profiles\n",
    "                links = [l for l in links if '/profil/spieler/' in l]\n",
    "                # Add the extracted player links to the players list\n",
    "                players.extend(links)\n",
    "                # Break the loop since the data has been extracted\n",
    "                break\n",
    "            except IndexError:\n",
    "                # Print a message and sleep for 10 seconds if an IndexError occurs\n",
    "                print('Index Error : Sleeping for 10 seconds before retrying')\n",
    "                sleep(10)\n",
    "        # Print the team name and year after data extraction is complete\n",
    "        print(team.split('/')[3], y)\n",
    "        # Sleep for a random time between 1 and 3 seconds to avoid rate-limiting\n",
    "        sleep(randint(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88813f9f-e98d-4488-8d2d-38cf1bc2db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the key 'URL' and values 'players'\n",
    "dict_players = {'URL' : players}\n",
    "\n",
    "# Convert the dictionary to a pandas dataframe 'df'\n",
    "df = pd.DataFrame(dict_players)\n",
    "\n",
    "# Remove duplicates in the 'URL' column\n",
    "df = df.drop_duplicates(subset = 'URL')\n",
    "\n",
    "# Reset the index of the dataframe to start from 0\n",
    "df.index = range(0,len(df))\n",
    "\n",
    "# Prefix the 'URL' column with 'https://www.transfermarkt.com'\n",
    "df['URL'] = 'https://www.transfermarkt.com' + df['URL'].astype(str)\n",
    "\n",
    "# Write the dataframe to a csv file at 'output/player_links.csv'\n",
    "df.to_csv('output/player_links.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
